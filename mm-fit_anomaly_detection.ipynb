{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-321031e04586>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/multimodal/lib/python3.6/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dgcca.dgcca import DGCCA\n",
    "from dgcca.anomaly_detection import CcaAnomalyDetector\n",
    "from utils.load_datasets import load_data\n",
    "from utils.load_models import load_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aca18hgw/.conda/envs/multimodal/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Config\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "name = 'ds_test'\n",
    "load_features = True\n",
    "load_dgcca = True\n",
    "\n",
    "### mm-fit network parameters\n",
    "num_epochs = 25\n",
    "eval_every = 1\n",
    "early_stop = 200\n",
    "checkpoint = 200\n",
    "weights_path = ''\n",
    "conv_layers = 3\n",
    "kernel_size = 11\n",
    "kernel_stride = 2\n",
    "f_in = 768 # number of input units in the first FC layer\n",
    "layers = 3 # number of FC layers\n",
    "hidden_units = 100 # number of hidden units\n",
    "dropout = 0.0\n",
    "output = 'output/' # path to output folder\n",
    "\n",
    "### mm-fit dataset parameters\n",
    "data_path = \"/mnt/fastdata/aca18hgw/mm-fit\"\n",
    "num_classes = 11\n",
    "window_stride = 0.2\n",
    "window_length = 5\n",
    "sampling_rate = 50\n",
    "skeleton_sampling_rate = 30\n",
    "target_sensor_sampling_rate = 50\n",
    "grouped = 'GGN'\n",
    "unseen_test_set = False\n",
    "\n",
    "# set devices\n",
    "parallel = False\n",
    "workers = 0\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print('Using {} GPUs'.format(torch.cuda.device_count()))\n",
    "        parallel = True\n",
    "    workers = torch.cuda.device_count() * 4\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "if not os.path.exists(output):\n",
    "    os.makedirs(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## define datasets\n",
    "IDs = ['01']#, '02', '03', '04', '06', '07', '08', '16', '17', '18']\n",
    "dataset_split = {'train_cca': 0.5, 'train_detector': 0.2, 'val': 0.15, 'test': 0.15}\n",
    "\n",
    "# All modalities available in MM-Fit\n",
    "MODALITIES = ['sw_l_acc', 'sw_l_gyr', 'sw_l_hr', 'sw_r_acc', 'sw_r_gyr', 'sw_r_hr', 'sp_l_acc', 'sp_l_gyr', 'sp_l_mag', 'sp_r_acc', 'sp_r_gyr', 'sp_r_mag', 'eb_l_acc', 'eb_l_gyr', 'pose_2d', 'pose_3d']\n",
    "# We use a subset of all modalities in this demo.\n",
    "MODALITIES_SUBSET = ['sw_l_acc', 'sw_l_gyr', 'sw_r_acc', 'sw_r_gyr', 'sp_r_acc', 'sp_r_gyr', 'eb_l_acc', 'eb_l_gyr', 'pose_3d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits: [36503, 14600, 10950, 10950]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding train_cca dataset: 100%|██████████| 286/286 [13:47<00:00,  2.19s/it]\n",
      "Embedding train_detector dataset: 100%|██████████| 115/115 [05:31<00:00,  2.08s/it]\n",
      "Embedding val dataset: 100%|██████████| 86/86 [04:08<00:00,  2.50s/it]\n",
      "Embedding test dataset: 100%|██████████| 86/86 [04:09<00:00,  2.54s/it]\n"
     ]
    }
   ],
   "source": [
    "if load_features:\n",
    "    datasets = {}\n",
    "    for split_name in dataset_split.keys():\n",
    "        with open('output/{}_{}.pkl'.format(name, split_name), 'rb') as f:\n",
    "            datasets[split_name] = pickle.load(f)\n",
    "else:\n",
    "    dataloaders = load_data(MODALITIES_SUBSET, data_path, ids=IDs, splits=[val for val in dataset_split.values()], loader=True, batch_size=batch_size, window_stride=window_stride, window_length=window_length, skeleton_sampling_rate=skeleton_sampling_rate, target_sensor_sampling_rate=target_sensor_sampling_rate, workers=workers)\n",
    "\n",
    "    models = load_models(modalities=MODALITIES_SUBSET, device=device)\n",
    "\n",
    "    for modality, model in models.items():\n",
    "        if parallel:\n",
    "            models[modality] = nn.DataParallel(model)\n",
    "        models[modality].eval()\n",
    "\n",
    "    all_embeddings = []\n",
    "    for split_name, loader in zip(dataset_split.keys(), dataloaders):\n",
    "        embeddings = {}\n",
    "        for modality in MODALITIES_SUBSET:\n",
    "            embeddings[modality] = []\n",
    "\n",
    "        length = len(loader)\n",
    "        with tqdm.tqdm(total=length) as pbar:\n",
    "            for i, (data, labels, reps) in enumerate(loader):\n",
    "                for modality in MODALITIES_SUBSET:\n",
    "                    embeddings[modality].append(models[modality](data[modality]).detach())\n",
    "\n",
    "                pbar.update(1)\n",
    "                pbar.set_description('Embedding {} dataset'.format(split_name))\n",
    "\n",
    "        for modality, data in embeddings.items():\n",
    "            cat = torch.cat(data).double()\n",
    "            embeddings[modality] = cat.reshape((cat.shape[0], -1))\n",
    "\n",
    "        with open('output/{}_{}.pkl'.format(name, split_name), 'wb') as f:\n",
    "            pickle.dump(embeddings, f, protocol=4)\n",
    "\n",
    "        all_embeddings.append(embeddings)\n",
    "\n",
    "    shapes = {}\n",
    "    for modality in MODALITIES_SUBSET:\n",
    "        shapes[modality] = all_embeddings[0][modality].shape[1]\n",
    "        \n",
    "    datasets = {}\n",
    "    for name, data in zip(dataset_split.keys(), all_embeddings):\n",
    "        datasets[name] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in datasets.keys():\n",
    "    del datasets[split]['pose_3d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = [256, 512]\n",
    "cca_input_dim = 64\n",
    "cca_lr = 1e-2\n",
    "cca_epochs = 3\n",
    "cca_dim = 10\n",
    "cca_truncparam = 1000\n",
    "cca_window_size = 150\n",
    "\n",
    "layer_sizes = [[modality.shape[1]] for modality in datasets['train_cca'].values()]\n",
    "for layers in layer_sizes:\n",
    "    layers.extend(hidden_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: -65.5386: 100%|██████████| 286/286 [00:53<00:00,  5.43it/s]\n",
      "Epoch [2/3], Loss: -69.7972: 100%|██████████| 286/286 [00:52<00:00,  5.46it/s]\n",
      "Epoch [3/3], Loss: -70.0739: 100%|██████████| 286/286 [00:52<00:00,  5.50it/s]\n",
      "Embedding training set:: 100%|██████████| 286/286 [00:06<00:00, 46.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decomposed data matrix for view 0\n",
      "Decomposed data matrix for view 1\n",
      "Decomposed data matrix for view 2\n",
      "Decomposed data matrix for view 3\n",
      "Decomposed data matrix for view 4\n",
      "Decomposed data matrix for view 5\n",
      "Decomposed data matrix for view 6\n",
      "Decomposed data matrix for view 7\n",
      "Decomposed M_tilde / solved for G\n",
      "Solved for U in view 0\n",
      "Solved for U in view 1\n",
      "Solved for U in view 2\n",
      "Solved for U in view 3\n",
      "Solved for U in view 4\n",
      "Solved for U in view 5\n",
      "Solved for U in view 6\n",
      "Solved for U in view 7\n"
     ]
    }
   ],
   "source": [
    "dgcca = DGCCA(layer_sizes, cca_input_dim, device=device)\n",
    "if load_dgcca:\n",
    "    dgcca.load_checkpoint('output/{}_dgcca.pth'.format(name))\n",
    "dgcca.train([output for output in datasets['train_cca'].values()], cca_epochs, lr=cca_lr, cca_dim=cca_dim, cca_hidden_dim=cca_truncparam, incremental=False)\n",
    "if not load_dgcca:\n",
    "    dgcca.save_checkpoint('output/{}_dgcca.pth'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating noise...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy.random' has no attribute 'default_rng'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c5935442cc3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold_classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodality\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_detector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcca_window_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/robust-mm/dgcca/anomaly_detection.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, embedding_dim, window, stride, method, plot)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'threshold'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Generating noise...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Getting data embeddings...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mdata_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdgcca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodality\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodality\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/robust-mm/dgcca/anomaly_detection.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'threshold'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Generating noise...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Getting data embeddings...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mdata_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdgcca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodality\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodality\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/robust-mm/dgcca/anomaly_detection.py\u001b[0m in \u001b[0;36mnoise_like\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy.random' has no attribute 'default_rng'"
     ]
    }
   ],
   "source": [
    "detector = CcaAnomalyDetector(dgcca)\n",
    "\n",
    "load_detector = False\n",
    "\n",
    "if load_detector:\n",
    "    detector.thresholds = np.load('output/adthresh.npy')\n",
    "    detector.classifier = detector.threshold_classifier\n",
    "else:\n",
    "    fig = detector.train([modality for modality in datasets['train_detector'].values()], stride=10, window=cca_window_size, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_single(data, labels, grace=0):\n",
    "    pred = detector.detect_anomalies(data, grace=grace)\n",
    "    #print(pred)\n",
    "    tp = ((labels == pred) & (pred == True)).sum()\n",
    "    tn = ((labels == pred) & (pred == False)).sum()\n",
    "    fp = ((labels != pred) & (pred == True)).sum()\n",
    "    fn = ((labels != pred) & (pred == False)).sum()\n",
    "    return (tp, tn, fp, fn)\n",
    "\n",
    "def reduce_data(data):\n",
    "    reduced = []\n",
    "    for modality in MODALITIES_SUBSET:\n",
    "        reduced.append(models[modality](data[modality]).detach().double())\n",
    "    reduced = [red.reshape((red.shape[0], -1)) for red in reduced]\n",
    "    return reduced\n",
    "\n",
    "def noise_like(data):\n",
    "    mean = data.mean().item()\n",
    "    std = data.std().item()\n",
    "    return torch.tensor(np.random.default_rng().normal(mean, std, data.shape))\n",
    "\n",
    "def evaluate(loader, n=10, corrupted=1, grace=0):\n",
    "    results = np.zeros((4))\n",
    "    with tqdm.tqdm(total=n) as eval_bar:\n",
    "        for i in range(n):\n",
    "            starttime = time.time()\n",
    "            data, _, _ = next(iter(loader))\n",
    "            data = reduce_data(data)\n",
    "            data = data[0:-1]\n",
    "            inftime = time.time() - starttime\n",
    "            labels = np.array([True]*(len(data)))\n",
    "            for modality in np.random.default_rng().choice(len(data), size=corrupted, replace=False):\n",
    "                data[modality] = noise_like(data[modality])\n",
    "                labels[modality] = False\n",
    "            #print(labels)\n",
    "            results += np.array(evaluate_single(data, labels, grace=grace))\n",
    "            alltime = time.time() - starttime\n",
    "            eval_bar.update(1)\n",
    "            eval_bar.set_description('Sample [{}/{}] | Accuracy: {:.1%} | Precision: {:.1%} | Recall: {:.1%}'.format(i+1, n, (results[0] + results[1])/results.sum(), results[0]/(results[0]+results[2]), results[0]/(results[0]+results[3])))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader, _, test_loader = load_data(MODALITIES_SUBSET, data, train_ids=TRAIN_W_IDs, val_ids = VAL_W_IDs, test_ids=TEST_W_IDs, loader=True, batch_size=cca_window_size, window_stride=window_stride, window_length=window_length, skeleton_sampling_rate=skeleton_sampling_rate, target_sensor_sampling_rate=target_sensor_sampling_rate, workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample [30/30] | Accuracy: 82.5% | Precision: 100.0% | Recall: 76.7%: 100%|██████████| 30/30 [04:38<00:00,  9.28s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([138.,  60.,   0.,  42.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = evaluate(test_loader, 30, 2, grace=2)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:multimodal]",
   "language": "python",
   "name": "conda-env-multimodal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
