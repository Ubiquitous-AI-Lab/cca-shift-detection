{
 "cells": [
  {
   "source": [
    "# CCA Anomaly detection on the MM-Fit dataset\n",
    "\n",
    "This notebook demonstrates use of Canonical Correlation Analysis (CCA) between modalities to detect anomalies.\n",
    "\n",
    "Results from the MM-Fit dataset are presented, using a pretrained classifier designed for Human Activity Recognition (HAR). The model has a multimodal architecture, with data from each modality feeding into an individual network to learn intra-modality features, before the individual networks are fused to learn cross-modality features. \n",
    "\n",
    "We attempt to detect corruption and distribution shift in each modality before the networks are fused, allowing us to remove or reconstruct these modalities before using them for classification. \n",
    "\n",
    "CCA learns a linear transformation of two datasets such that the transformed data is maximally correlated. We learn these transformations on clean data, expecting that at test time a pair of clean modalities will have a high correlation, but a corrupt modality will havea low correlation.\n",
    "\n",
    "Deep Generalised Canonical Correlation Analysis (DGCCA) can be applied to more that two datasets, and can learn nonlinear transformations. Linear Generalised CCA (GCCA) is used to derive a loss function to train a deep network for each modality, transforming the reprentations into a form that GCCA can learn linear transformations of.\n",
    "\n",
    "We proceed by generating the intermediate representations of the raw MM-Fit data used for anomaly detection, training the deep and linear portions of the DGCCA, and then training anomaly detector thresholds."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "from dgcca.dgcca import DGCCA\n",
    "from dgcca.anomaly_detection import CcaAnomalyDetector\n",
    "from mm_fit.utils.dataset import SequentialStridedSampler\n",
    "from utils.load_datasets import load_data\n",
    "from utils.load_models import load_models\n",
    "from utils.noise import GMMNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Config\n",
    "\n",
    "### notebook settings\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "name = 'nb_test'      # name used to load/save datasets and training checkpoints\n",
    "load_features = False  # load modalitiy specific autoenceoder embeddings or generate them\n",
    "save_features = True   # save generated modality specific embeddings\n",
    "load_dgcca = False     # load trained dgcca network heads\n",
    "\n",
    "### mm-fit network parameters\n",
    "num_epochs = 25\n",
    "eval_every = 1\n",
    "early_stop = 200\n",
    "checkpoint = 200\n",
    "weights_path = 'output/mmfit_demo_1610541736_checkpoint_0.pth' # path to mm-fit classification network checkpoint\n",
    "conv_layers = 3\n",
    "kernel_size = 11\n",
    "kernel_stride = 2\n",
    "f_in = 768 # number of input units in the first FC layer\n",
    "layers = 3 # number of FC layers\n",
    "hidden_units = 100 # number of hidden units\n",
    "dropout = 0.0\n",
    "output = 'output/' # path to output folder\n",
    "\n",
    "### mm-fit dataset parameters\n",
    "data_path = \"../data\" # mm-fit dataset path\n",
    "workout_ids = ['01']#, '02', '03', '06', '16', '17', '18'] # workout data to use\n",
    "dataset_split = {'train_cca': 0.7, 'train_detector': 0.1, 'val': 0.1, 'test': 0.1} # dataset split names and proportions\n",
    "samplers = [RandomSampler, lambda x: SequentialStridedSampler(x, 1), lambda x: SequentialStridedSampler(x, 1), lambda x: SequentialStridedSampler(x, 1)]\n",
    "MODALITIES_SUBSET = ['sw_l_acc', 'sw_l_gyr', 'sw_r_acc', 'sw_r_gyr', 'sp_r_acc', 'sp_r_gyr', 'eb_l_acc', 'eb_l_gyr', 'pose_3d'] # modalities to load model and data for\n",
    "#ALL_MODALITIES = ['sw_l_acc', 'sw_l_gyr', 'sw_l_hr', 'sw_r_acc', 'sw_r_gyr', 'sw_r_hr', 'sp_l_acc', 'sp_l_gyr', 'sp_l_mag', 'sp_r_acc', 'sp_r_gyr', 'sp_r_mag', 'eb_l_acc', 'eb_l_gyr', 'pose_2d', 'pose_3d'] # all modalities available in dataset\n",
    "num_classes = 11\n",
    "window_stride = 0.2\n",
    "window_length = 5\n",
    "sampling_rate = 50\n",
    "skeleton_sampling_rate = 30\n",
    "target_sensor_sampling_rate = 50\n",
    "grouped = 'GGN'\n",
    "unseen_test_set = False\n",
    "\n",
    "# set devices - 'cpu' default, 'cuda:0' if available, sets models as nn.DataParallel if multiple gpus available\n",
    "parallel = False\n",
    "workers = 0\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print('Using {} GPUs'.format(torch.cuda.device_count()))\n",
    "        parallel = True\n",
    "    workers = torch.cuda.device_count() * 4 # Set dataloader workers for multipl gpus\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "if not os.path.exists(output):\n",
    "    os.makedirs(output)"
   ]
  },
  {
   "source": [
    "We run the raw data through our pretrained autoencoders to obtain the intermediate dataset needed for dgcca training."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intermediate_rep(loader, name, models, modalities, noise=None):\n",
    "    embeddings = {}\n",
    "    for modality in modalities:\n",
    "        embeddings[modality] = []\n",
    "\n",
    "    length = len(loader)\n",
    "    with tqdm.tqdm(total=length) as pbar:\n",
    "        for i, (data, labels, reps) in enumerate(loader):\n",
    "            for modality in modalities:\n",
    "                input_data = data[modality] if noise is None else noise(data[modality], modality)\n",
    "                embeddings[modality].append(models[modality](input_data).detach())\n",
    "\n",
    "            pbar.update(1)\n",
    "            pbar.set_description('Embedding {} dataset'.format(name))\n",
    "\n",
    "    for modality, data in embeddings.items():\n",
    "        cat = torch.cat(data).double()\n",
    "        embeddings[modality] = cat.reshape((cat.shape[0], -1))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset splits: [51103, 7300, 7300, 7300]\n"
     ]
    }
   ],
   "source": [
    "dataloaders = load_data(MODALITIES_SUBSET, data_path, ids=workout_ids, splits=[val for val in dataset_split.values()], loader=True, samplers=samplers, batch_size=batch_size, window_stride=window_stride, window_length=window_length, skeleton_sampling_rate=skeleton_sampling_rate, target_sensor_sampling_rate=target_sensor_sampling_rate, workers=workers)\n",
    "\n",
    "models = load_models(modalities=MODALITIES_SUBSET, device=device, model_wp=weights_path) # load individual modality autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Embedding train_cca dataset: 100%|██████████| 571/571 [31:23<00:00,  3.30s/it]\n"
     ]
    }
   ],
   "source": [
    "if load_features:\n",
    "    with open('output/{}_{}.pkl'.format(name, 'train_cca'), 'rb') as f:\n",
    "            train_cca = pickle.load(f)\n",
    "else:\n",
    "    train_cca = get_intermediate_rep(dataloaders[0], 'train_cca', models, MODALITIES_SUBSET)\n",
    "    if save_features:\n",
    "        with open('output/{}_{}.pkl'.format(name, 'train_cca'), 'wb') as f:\n",
    "            pickle.dump(train_cca, f, protocol=4)\n",
    "\n",
    "shapes = {}\n",
    "for modality in [mod for mod in MODALITIES_SUBSET if mod != 'pose_3d']:\n",
    "    shapes[modality] = train_cca[modality].shape[1]\n",
    "\n",
    "del train_cca['pose_3d']"
   ]
  },
  {
   "source": [
    "Define the input, output and hidden layer sizes for the networks in the nonlinear portion of DGCCA, as well as DGCCA parameters."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[384, 256, 512]\n[384, 256, 512]\n[384, 256, 512]\n[384, 256, 512]\n[384, 256, 512]\n[384, 256, 512]\n[384, 256, 512]\n[384, 256, 512]\n"
     ]
    }
   ],
   "source": [
    "hidden_layers = [256, 512]\n",
    "cca_input_dim = 64\n",
    "cca_lr = 1e-2\n",
    "cca_epochs = 3\n",
    "cca_dim = 10\n",
    "cca_truncparam = 1000\n",
    "cca_window_size = 128\n",
    "\n",
    "layer_sizes = [[modality.shape[1]] for modality in train_cca.values()]\n",
    "for layers in layer_sizes:\n",
    "    layers.extend(hidden_layers)\n",
    "    print(layers)"
   ]
  },
  {
   "source": [
    "Train or load the weights for the nonlinear networks, and train the linear GCCA weights. The linear GCCA requires the embeddings of the training set from the nonlinear networks."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch [1/3], Loss: -67.2374: 100%|██████████| 571/571 [02:40<00:00,  3.56it/s]\n",
      "Epoch [2/3], Loss: -69.4550: 100%|██████████| 571/571 [02:36<00:00,  3.64it/s]\n",
      "Epoch [3/3], Loss: -69.4553: 100%|██████████| 571/571 [02:30<00:00,  3.81it/s]\n",
      "Embedding training set:: 100%|██████████| 571/571 [00:22<00:00, 25.06it/s]\n",
      "Decomposed data matrix for view 0\n",
      "Decomposed data matrix for view 1\n",
      "Decomposed data matrix for view 2\n",
      "Decomposed data matrix for view 3\n",
      "Decomposed data matrix for view 4\n",
      "Decomposed data matrix for view 5\n",
      "Decomposed data matrix for view 6\n",
      "Decomposed data matrix for view 7\n",
      "Decomposed M_tilde / solved for G\n",
      "Solved for U in view 0\n",
      "Solved for U in view 1\n",
      "Solved for U in view 2\n",
      "Solved for U in view 3\n",
      "Solved for U in view 4\n",
      "Solved for U in view 5\n",
      "Solved for U in view 6\n",
      "Solved for U in view 7\n"
     ]
    }
   ],
   "source": [
    "dgcca = DGCCA(layer_sizes, cca_input_dim, device=device)\n",
    "if load_dgcca:\n",
    "    dgcca.load_checkpoint('output/{}_dgcca.pth'.format(name))\n",
    "dgcca.train([output for output in train_cca.values()], cca_epochs, lr=cca_lr, cca_dim=cca_dim, cca_hidden_dim=cca_truncparam, incremental=False)\n",
    "if not load_dgcca:\n",
    "    dgcca.save_checkpoint('output/{}_dgcca.pth'.format(name))"
   ]
  },
  {
   "source": [
    "The anomaly detector uses the pairwise correlations between each modality to decide which modalities, if any, are corrupt. A second dataset is used to train a threshold correlation for each pair to decide whether a pair contains a corrupted modality or not. The threshold is chosen by comparing the distribution of correlations when both modalities are clean, and when one modality has had noise added.\n",
    "\n",
    "The clean and corrupt distributions for each pair are shown below, giving an idea of the separability of correlations from each pair. detector.type_1 and detector.type_2 give probabilities of type 1 and 2 errors respectively.\n",
    "\n",
    "We first generate the intermediate representations of both clean and corrupt data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_components = 5     # number of gaussian mixture model components for noise generation\n",
    "snr = 1.5              # signal to noise ratio\n",
    "load_detector = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Embedding ad_clean dataset: 100%|██████████| 571/571 [33:44<00:00,  3.54s/it]\n",
      "Fitting GMM 2 for eb_l_gyr: 100%|█████████▉| 7.9999999999999964/8 [01:14<00:00,  9.35s/it]\n",
      "Embedding ad_corrupt dataset: 100%|██████████| 571/571 [1:01:15<00:00,  6.44s/it]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'pose_3d'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3b139dd0fc65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pose_3d'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mcorrupt_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pose_3d'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'pose_3d'"
     ]
    }
   ],
   "source": [
    "if load_features:\n",
    "    with open('output/{}_{}.pkl'.format(name, 'clean'), 'rb') as f:\n",
    "        clean_data = pickle.load(f)\n",
    "    with open('output/{}_{}.pkl'.format(name, 'corrupt'), 'rb') as f:\n",
    "        corrupt_data = pickle.load(f)\n",
    "else:\n",
    "    clean_data = get_intermediate_rep(dataloaders[1], 'ad_clean', models, [mod for mod in MODALITIES_SUBSET if mod != 'pose_3d'])\n",
    "\n",
    "    noise_gen = GMMNoise(data_path, [mod for mod in MODALITIES_SUBSET if mod != 'pose_3d'], workout_ids, gmm_components)\n",
    "    noise = lambda data, modality: noise_gen.add_noise(data, snr=snr, modality=modality)\n",
    "\n",
    "    corrupt_data = get_intermediate_rep(dataloaders[1], 'ad_corrupt', models, [mod for mod in MODALITIES_SUBSET if mod != 'pose_3d'], noise=noise)\n",
    "    if save_features:\n",
    "        with open('output/{}_{}.pkl'.format(name, 'clean'), 'wb') as f:\n",
    "            pickle.dump(clean_data, f, protocol=4)\n",
    "        with open('output/{}_{}.pkl'.format(name, 'corrupt'), 'wb') as f:\n",
    "            pickle.dump(corrupt_data, f, protocol=4)\n",
    "\n",
    "\n",
    "del clean_data['pose_3d']\n",
    "del corrupt_data['pose_3d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import dgcca.anomaly_detection\n",
    "import utils.noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'utils.noise' from 'c:\\\\Users\\\\harry\\\\Documents\\\\Work\\\\Dissertation\\\\robust-mm\\\\utils\\\\noise.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "reload(dgcca.anomaly_detection)\n",
    "reload(utils.noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dgcca.anomaly_detection.CcaAnomalyDetector(dgcca, noise_gen)\n",
    "\n",
    "if load_detector:\n",
    "    detector.thresholds = np.load('output/adthresh.npy')\n",
    "    detector.classifier = detector.threshold_classifier\n",
    "else:\n",
    "    fig = detector.train([mod for mod in clean_data.values()], [mod for mod in corrupt_data.values()], stride=20, window=cca_window_size, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_single(data, labels, grace=0):\n",
    "    pred = detector.detect_anomalies(data, grace=grace)\n",
    "    #print(pred)\n",
    "    tp = ((labels == pred) & (pred == True)).sum()\n",
    "    tn = ((labels == pred) & (pred == False)).sum()\n",
    "    fp = ((labels != pred) & (pred == True)).sum()\n",
    "    fn = ((labels != pred) & (pred == False)).sum()\n",
    "    return (tp, tn, fp, fn)\n",
    "\n",
    "def reduce_data(data):\n",
    "    reduced = []\n",
    "    for modality in MODALITIES_SUBSET:\n",
    "        reduced.append(models[modality](data[modality]).detach().double())\n",
    "    reduced = [red.reshape((red.shape[0], -1)) for red in reduced]\n",
    "    return reduced\n",
    "\n",
    "def noise_like(data):\n",
    "    mean = data.mean().item()\n",
    "    std = data.std().item()\n",
    "    return torch.tensor(np.random.default_rng().normal(mean, std, data.shape))\n",
    "\n",
    "def evaluate(loader, n=10, corrupted=1, grace=0):\n",
    "    results = np.zeros((4))\n",
    "    with tqdm.tqdm(total=n) as eval_bar:\n",
    "        for i in range(n):\n",
    "            starttime = time.time()\n",
    "            data, _, _ = next(iter(loader))\n",
    "            data = reduce_data(data)\n",
    "            data = data[0:-1]\n",
    "            inftime = time.time() - starttime\n",
    "            labels = np.array([True]*(len(data)))\n",
    "            for modality in np.random.default_rng().choice(len(data), size=corrupted, replace=False):\n",
    "                data[modality] = noise_like(data[modality])\n",
    "                labels[modality] = False\n",
    "            results += np.array(evaluate_single(data, labels, grace=grace))\n",
    "            alltime = time.time() - starttime\n",
    "            eval_bar.update(1)\n",
    "            eval_bar.set_description('Sample [{}/{}] | Accuracy: {:.1%} | Precision: {:.1%} | Recall: {:.1%}'.format(i+1, n, (results[0] + results[1])/results.sum(), results[0]/(results[0]+results[2]), results[0]/(results[0]+results[3])))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Sample [30/30] | Accuracy: 94.6% | Precision: 98.7% | Recall: 86.7%: 100%|██████████| 30/30 [01:38<00:00,  3.28s/it]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 78., 149.,   1.,  12.])"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "results = evaluate(dataloaders[2], 30, 5, grace=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('diss': conda)",
   "metadata": {
    "interpreter": {
     "hash": "5030eca79e228eb9e94d63871aedbeee6ecf1ee1f1dbb6f0b71ec835d9bf8890"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}